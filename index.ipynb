{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions to Linear Models - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, you'll practice many concepts learned in this section, from adding interactions and polynomials to your model to AIC and BIC!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You will be able to:\n",
    "- Build a linear regression model with polynomial features/interactions\n",
    "- Perform regularization\n",
    "- Use AIC and BIC to select the best value for the regularization parameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at a Baseline Boston Housing Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Boston housing data set, use all the predictors in their scaled version (using `preprocessing.scale`. Look at a baseline model using *scaled variables* as predictors. Use 5-fold cross-validation this time and use the $R^2$ score to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset, create X and y\n",
    "X = pd.DataFrame(preprocessing.scale(load_boston()['data']), columns = load_boston()['feature_names'])\n",
    "y = pd.DataFrame(preprocessing.scale(load_boston()['target']), columns=['PRICE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model\n",
    "regression = LinearRegression()\n",
    "crossvalidation = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "baseline = np.mean(cross_val_score(regression, X, y, scoring=\"r2\", cv=crossvalidation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7176778617934925"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include interactions\n",
    "\n",
    "Look at all the possible combinations of variables for interactions by adding interactions one by one to the baseline model. Next, evaluate that model using 5-fold classification and store the $R^2$ to compare it with the baseline model.\n",
    "\n",
    "You've created code for this before in the interactions lab, yet this time, you have scaled the variables so the outcomes may look different. \n",
    "\n",
    "Print the 7 most important interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "from itertools import combinations\n",
    "columns = list(X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Create list of all possible combinations\n",
    "combs = list(combinations(columns,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_performance = []\n",
    "\n",
    "for interaction in combs:\n",
    "    X[interaction] = X[interaction[0]]*X[interaction[1]]\n",
    "    updated = np.mean(cross_val_score(regression, X, y, scoring=\"r2\", cv=crossvalidation))\n",
    "    interaction_performance.append({'Interaction': interaction, 'R2':updated})\n",
    "    X.drop([interaction], axis=1, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56      (RM, LSTAT)\n",
       "53        (RM, TAX)\n",
       "52        (RM, RAD)\n",
       "54    (RM, PTRATIO)\n",
       "25      (INDUS, RM)\n",
       "42        (NOX, RM)\n",
       "50        (RM, AGE)\n",
       "Name: Interaction, dtype: object"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interactions = pd.DataFrame(interaction_performance)\n",
    "df_interactions.sort_values(by=['R2'], ascending=False, inplace=True)\n",
    "most_important = df_interactions[0:7]['Interaction']\n",
    "most_important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to include the 7 most important interactions in your data set by adding 7 columns. Name the columns \"var1_var2\" with var1 and var2 the two variables in the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>(RM, LSTAT)</th>\n",
       "      <th>(RM, TAX)</th>\n",
       "      <th>(RM, RAD)</th>\n",
       "      <th>(RM, PTRATIO)</th>\n",
       "      <th>(INDUS, RM)</th>\n",
       "      <th>(NOX, RM)</th>\n",
       "      <th>(RM, AGE)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "      <td>-0.444930</td>\n",
       "      <td>-0.275757</td>\n",
       "      <td>-0.406574</td>\n",
       "      <td>-0.603547</td>\n",
       "      <td>-0.532772</td>\n",
       "      <td>-0.059659</td>\n",
       "      <td>-0.049646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "      <td>-0.095668</td>\n",
       "      <td>-0.191813</td>\n",
       "      <td>-0.168607</td>\n",
       "      <td>-0.058883</td>\n",
       "      <td>-0.115279</td>\n",
       "      <td>-0.143814</td>\n",
       "      <td>0.071331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "      <td>-1.550451</td>\n",
       "      <td>-1.266461</td>\n",
       "      <td>-1.113245</td>\n",
       "      <td>-0.388783</td>\n",
       "      <td>-0.761138</td>\n",
       "      <td>-0.949544</td>\n",
       "      <td>-0.340960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "      <td>-1.383713</td>\n",
       "      <td>-1.124148</td>\n",
       "      <td>-0.765197</td>\n",
       "      <td>0.114875</td>\n",
       "      <td>-1.328183</td>\n",
       "      <td>-0.848901</td>\n",
       "      <td>-0.823092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "      <td>-1.261136</td>\n",
       "      <td>-1.358947</td>\n",
       "      <td>-0.925023</td>\n",
       "      <td>0.138869</td>\n",
       "      <td>-1.605599</td>\n",
       "      <td>-1.026210</td>\n",
       "      <td>-0.628023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "\n",
       "        DIS       RAD       TAX   PTRATIO         B     LSTAT  (RM, LSTAT)  \\\n",
       "0  0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562    -0.444930   \n",
       "1  0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439    -0.095668   \n",
       "2  0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727    -1.550451   \n",
       "3  1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517    -1.383713   \n",
       "4  1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501    -1.261136   \n",
       "\n",
       "   (RM, TAX)  (RM, RAD)  (RM, PTRATIO)  (INDUS, RM)  (NOX, RM)  (RM, AGE)  \n",
       "0  -0.275757  -0.406574      -0.603547    -0.532772  -0.059659  -0.049646  \n",
       "1  -0.191813  -0.168607      -0.058883    -0.115279  -0.143814   0.071331  \n",
       "2  -1.266461  -1.113245      -0.388783    -0.761138  -0.949544  -0.340960  \n",
       "3  -1.124148  -0.765197       0.114875    -1.328183  -0.848901  -0.823092  \n",
       "4  -1.358947  -0.925023       0.138869    -1.605599  -1.026210  -0.628023  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create updated dataframe\n",
    "df_inter = X.copy()\n",
    "\n",
    "for interaction in most_important:\n",
    "    df_inter[interaction] = df_inter[interaction[0]]*df_inter[interaction[1]]\n",
    "\n",
    "df_inter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7897850685984782"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions = np.mean(cross_val_score(regression, df_inter, y, scoring=\"r2\", cv=crossvalidation))\n",
    "interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include Polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try polynomials of 2, 3 and 4 for each variable, in a similar way you did for interactions (by looking at your baseline model and seeing how $R^2$ increases). Do understand that when going for a polynomial of 4, the particular column is raised to the power of 2 and 3 as well in other terms. We only want to include \"pure\" polynomials, so make sure no interactions are included. We want the result to return a list that contain tuples of the form:\n",
    "\n",
    "`(var_name, degree, R2)`, so eg. `('DIS', 3, 0.732)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 polynomials: [('RM', 4, 0.8), ('RM', 2, 0.782), ('LSTAT', 4, 0.782), ('RM', 3, 0.781), ('LSTAT', 3, 0.774), ('LSTAT', 2, 0.772), ('DIS', 3, 0.737), ('DIS', 2, 0.732), ('DIS', 4, 0.731), ('TAX', 4, 0.724)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "polynomials = []\n",
    "for col in X.columns:\n",
    "    for degree in [2,3,4]:\n",
    "        data = X.copy()\n",
    "        poly = PolynomialFeatures(degree, include_bias=False)\n",
    "        X_temp = pd.DataFrame(poly.fit_transform(X[[col]]))\n",
    "        data = pd.concat([data.drop(col, axis=1),pd.DataFrame(X_temp)], axis = 1)\n",
    "        score = np.mean(cross_val_score(regression, data, y, scoring=\"r2\", cv=crossvalidation))\n",
    "        if score > baseline: polynomials.append((col, degree, round(score,3)))\n",
    "print(\"Top 10 polynomials: %s\" %sorted(polynomials, key=lambda poly: poly[2], reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each variable, print out the maximum R2 possible when including Polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which two variables seem to benefit most from adding Polynomial terms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Polynomials for the two features that seem to benefit the most, as in have the best R squared compared to the baseline model. For each of the two feature, raise to the Polynomial that generates the best result. Make sure to start from the data set `df_inter` so the final data set has both interactions and polynomials in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "df_poly = df_inter.copy()\n",
    "\n",
    "for feat in ['RM','LSTAT']:\n",
    "    for degree in [2,3,4]:\n",
    "        df_poly[f\"{feat}^{degree}\"] = df_poly[feat]**degree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check out your final data set and make sure that your interaction terms as well as your polynomial terms are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>...</th>\n",
       "      <th>(RM, PTRATIO)</th>\n",
       "      <th>(INDUS, RM)</th>\n",
       "      <th>(NOX, RM)</th>\n",
       "      <th>(RM, AGE)</th>\n",
       "      <th>RM^2</th>\n",
       "      <th>RM^3</th>\n",
       "      <th>RM^4</th>\n",
       "      <th>LSTAT^2</th>\n",
       "      <th>LSTAT^3</th>\n",
       "      <th>LSTAT^4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.603547</td>\n",
       "      <td>-0.532772</td>\n",
       "      <td>-0.059659</td>\n",
       "      <td>-0.049646</td>\n",
       "      <td>0.171124</td>\n",
       "      <td>0.070789</td>\n",
       "      <td>0.029284</td>\n",
       "      <td>1.156834</td>\n",
       "      <td>-1.244247</td>\n",
       "      <td>1.338266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058883</td>\n",
       "      <td>-0.115279</td>\n",
       "      <td>-0.143814</td>\n",
       "      <td>0.071331</td>\n",
       "      <td>0.037743</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.242497</td>\n",
       "      <td>-0.119415</td>\n",
       "      <td>0.058805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.388783</td>\n",
       "      <td>-0.761138</td>\n",
       "      <td>-0.949544</td>\n",
       "      <td>-0.340960</td>\n",
       "      <td>1.645354</td>\n",
       "      <td>2.110519</td>\n",
       "      <td>2.707191</td>\n",
       "      <td>1.461022</td>\n",
       "      <td>-1.765977</td>\n",
       "      <td>2.134585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114875</td>\n",
       "      <td>-1.328183</td>\n",
       "      <td>-0.848901</td>\n",
       "      <td>-0.823092</td>\n",
       "      <td>1.032871</td>\n",
       "      <td>1.049709</td>\n",
       "      <td>1.066822</td>\n",
       "      <td>1.853728</td>\n",
       "      <td>-2.523882</td>\n",
       "      <td>3.436308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138869</td>\n",
       "      <td>-1.605599</td>\n",
       "      <td>-1.026210</td>\n",
       "      <td>-0.628023</td>\n",
       "      <td>1.509401</td>\n",
       "      <td>1.854414</td>\n",
       "      <td>2.278290</td>\n",
       "      <td>1.053705</td>\n",
       "      <td>-1.081630</td>\n",
       "      <td>1.110295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "\n",
       "        DIS       RAD       TAX  ...  (RM, PTRATIO)  (INDUS, RM)  (NOX, RM)  \\\n",
       "0  0.140214 -0.982843 -0.666608  ...      -0.603547    -0.532772  -0.059659   \n",
       "1  0.557160 -0.867883 -0.987329  ...      -0.058883    -0.115279  -0.143814   \n",
       "2  0.557160 -0.867883 -0.987329  ...      -0.388783    -0.761138  -0.949544   \n",
       "3  1.077737 -0.752922 -1.106115  ...       0.114875    -1.328183  -0.848901   \n",
       "4  1.077737 -0.752922 -1.106115  ...       0.138869    -1.605599  -1.026210   \n",
       "\n",
       "   (RM, AGE)      RM^2      RM^3      RM^4   LSTAT^2   LSTAT^3   LSTAT^4  \n",
       "0  -0.049646  0.171124  0.070789  0.029284  1.156834 -1.244247  1.338266  \n",
       "1   0.071331  0.037743  0.007332  0.001425  0.242497 -0.119415  0.058805  \n",
       "2  -0.340960  1.645354  2.110519  2.707191  1.461022 -1.765977  2.134585  \n",
       "3  -0.823092  1.032871  1.049709  1.066822  1.853728 -2.523882  3.436308  \n",
       "4  -0.628023  1.509401  1.854414  2.278290  1.053705 -1.081630  1.110295  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Your code here\n",
    "df_poly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the R-squared of the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8061549447223175"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "full = np.mean(cross_val_score(regression, df_poly, y, scoring=\"r2\", cv=crossvalidation))\n",
    "full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best Lasso regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've learned that, when using Lasso regularization, your coefficients shrink to 0 when using a higher regularization parameter. Now the question is which value we should choose for the regularization parameter. \n",
    "\n",
    "This is where the AIC and BIC come in handy! We'll use both criteria in what follows and perform cross-validation to select an optimal value of the regularization parameter alpha of the Lasso estimator.\n",
    "\n",
    "Read the page here: https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html and create a similar plot as the first one listed on the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LassoCV, LassoLarsCV, LassoLarsIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_bic = LassoLarsIC(criterion='bic')\n",
    "model_bic.fit(df_poly, y)\n",
    "alpha_bic_ = model_bic.alpha_\n",
    "\n",
    "model_aic = LassoLarsIC(criterion='aic')\n",
    "model_aic.fit(df_poly, y)\n",
    "alpha_aic_ = model_aic.alpha_\n",
    "\n",
    "\n",
    "def plot_ic_criterion(model, name, color):\n",
    "    alpha_ = model.alpha_\n",
    "    alphas_ = model.alphas_\n",
    "    criterion_ = model.criterion_\n",
    "    plt.plot(-np.log10(alphas_), criterion_, '--', color=color, linewidth=2, label= name)\n",
    "    plt.axvline(-np.log10(alpha_), color=color, linewidth=2,\n",
    "                label='alpha for %s ' % name)\n",
    "    plt.xlabel('-log(alpha)')\n",
    "    plt.ylabel('criterion')\n",
    "\n",
    "plt.figure()\n",
    "plot_ic_criterion(model_aic, 'AIC', 'green')\n",
    "plot_ic_criterion(model_bic, 'BIC', 'blue')\n",
    "plt.legend()\n",
    "plt.title('Information-criterion for model selection');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the final result\n",
    "\n",
    "Finally, use the best value for regularization parameter according to AIC and BIC and compare the R squared parameters and MSE using train-test-split. Compare with the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.740484003564715\n",
      "Testing r^2: 0.7330271923024104\n",
      "Training MSE: 0.24810377359933006\n",
      "Testing MSE: 0.30200468351503285\n"
     ]
    }
   ],
   "source": [
    "# Code for baseline model\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "linreg_all = LinearRegression()\n",
    "linreg_all.fit(X_train, y_train)\n",
    "print('Training r^2:', linreg_all.score(X_train, y_train))\n",
    "print('Testing r^2:', linreg_all.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, linreg_all.predict(X_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_test, linreg_all.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.846948495375705\n",
      "Testing r^2: 0.7282128945905586\n",
      "Training MSE: 0.15835573259825983\n",
      "Testing MSE: 0.2422512419689952\n"
     ]
    }
   ],
   "source": [
    "# code for lasso with alpha from AIC\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_inter, y)\n",
    "\n",
    "lasso = Lasso(alpha= model_aic.alpha_) \n",
    "lasso.fit(X_train, y_train)\n",
    "print('Training r^2:', lasso.score(X_train, y_train))\n",
    "print('Testing r^2:', lasso.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_test, lasso.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.8455405853751121\n",
      "Testing r^2: 0.7293236512801988\n",
      "Training MSE: 0.15981243581802612\n",
      "Testing MSE: 0.24126119430950319\n"
     ]
    }
   ],
   "source": [
    "# code for lasso with alpha from BIC\n",
    "\n",
    "lasso = Lasso(alpha= model_bic.alpha_) \n",
    "lasso.fit(X_train, y_train)\n",
    "print('Training r^2:', lasso.score(X_train, y_train))\n",
    "print('Testing r^2:', lasso.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_test, lasso.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up - Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Lasso Path\n",
    "\n",
    "From this section, you know that when using lasso, more parameters shrink to zero as your regularization parameter goes up. In Scikit-Learn there is a function lasso_path which visualizes the shrinkage of the coefficients while alpha changes. Try this out yourself!\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIC and BIC for subset selection\n",
    "This notebook shows how you can use AIC and BIC purely for feature selection. Try this code out on our Boston Housing data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xavierbourretsicotte.github.io/subset_selection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now know how to create better linear models and how to use AIC and BIC for both feature selection and to optimize your regularization parameter when performing Ridge and Lasso. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
